{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzfmF76sURjoKlYEWNzjjr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowripreetham/SJSU_Apache_Beam/blob/main/Apache_Beam_Data_Engineering_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtA4I8Anv5px",
        "outputId": "9df52234-ad77-4b9f-ee4c-cc07cb0383d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.5/173.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.6/218.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.2/319.2 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.7/276.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.1/529.1 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.6/86.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.16 requires dill>=0.3.8, but you have dill 0.3.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m✅ Apache Beam installed and ready to use!\n"
          ]
        }
      ],
      "source": [
        "# --- Step 1: Setup Environment ---\n",
        "!pip install --quiet apache-beam[gcp]\n",
        "\n",
        "import apache_beam as beam\n",
        "print(\"✅ Apache Beam installed and ready to use!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Pipeline I/O Example ---\n",
        "\n",
        "sample_data = [\n",
        "    \"2984641,Emily,35,cardio,2021-09-01\",\n",
        "    \"9454384,Riikka,86,ortho,2021-07-21\",\n",
        "    \"9266396,Fanny,86,ortho,2021-06-03\",\n",
        "    \"5247541,Urooj,35,cardio,2021-08-21\",\n",
        "    \"6482736,Ali,50,neuro,2021-09-12\",\n",
        "]\n",
        "\n",
        "with open(\"dept_data.txt\", \"w\") as f:\n",
        "    for line in sample_data:\n",
        "        f.write(line + \"\\n\")\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "    (\n",
        "        p\n",
        "        | \"Read Input File\" >> beam.io.ReadFromText(\"dept_data.txt\")\n",
        "        | \"Write Output File\" >> beam.io.WriteToText(\"output_data\")\n",
        "    )\n",
        "\n",
        "print(\"✅ File created and processed into output_data.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "UjKezGUWwCj7",
        "outputId": "67eceaff-4d95-4df3-c392-6531e033ede3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ File created and processed into output_data.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 3: Map and Filter Example ---\n",
        "\n",
        "def parse_line(line):\n",
        "    patient_id, name, dept_id, dept_name, date = line.split(\",\")\n",
        "    return {\"patient_id\": patient_id, \"name\": name, \"dept\": dept_name, \"visit_date\": date}\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "    (\n",
        "        p\n",
        "        | \"Read\" >> beam.io.ReadFromText(\"dept_data.txt\")\n",
        "        | \"Parse CSV\" >> beam.Map(parse_line)\n",
        "        | \"Filter cardio dept\" >> beam.Filter(lambda x: x[\"dept\"] == \"cardio\")\n",
        "        | \"Print results\" >> beam.Map(print)\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FENLMBkwFCe",
        "outputId": "8f88b0b4-70eb-47d1-986f-8ee5d22f6d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'patient_id': '2984641', 'name': 'Emily', 'dept': 'cardio', 'visit_date': '2021-09-01'}\n",
            "{'patient_id': '5247541', 'name': 'Urooj', 'dept': 'cardio', 'visit_date': '2021-08-21'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 4: ParDo Example ---\n",
        "class ExtractAndTagPatients(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        patient_id, name, dept_id, dept_name, date = element.split(\",\")\n",
        "        yield (name, dept_name)\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "    (\n",
        "        p\n",
        "        | \"Read\" >> beam.io.ReadFromText(\"dept_data.txt\")\n",
        "        | \"Extract Name and Dept\" >> beam.ParDo(ExtractAndTagPatients())\n",
        "        | \"Print Results\" >> beam.Map(print)\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq7iTVRVwH0V",
        "outputId": "07d213de-78b8-472d-f2dd-1196c88ddd68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Emily', 'cardio')\n",
            "('Riikka', 'ortho')\n",
            "('Fanny', 'ortho')\n",
            "('Urooj', 'cardio')\n",
            "('Ali', 'neuro')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5: Partition Example ---\n",
        "\n",
        "def partition_fn(record, n_partitions):\n",
        "    if \"cardio\" in record:\n",
        "        return 0\n",
        "    elif \"ortho\" in record:\n",
        "        return 1\n",
        "    else:\n",
        "        return 2\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "    results = (\n",
        "        p\n",
        "        | \"Read data\" >> beam.io.ReadFromText(\"dept_data.txt\")\n",
        "        | \"Partition data\" >> beam.Partition(partition_fn, 3)\n",
        "    )\n",
        "\n",
        "cardio, ortho, others = results\n",
        "cardio | \"Write cardio\" >> beam.io.WriteToText(\"cardio_output\")\n",
        "ortho  | \"Write ortho\"  >> beam.io.WriteToText(\"ortho_output\")\n",
        "others | \"Write others\" >> beam.io.WriteToText(\"other_output\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXlwsE99wJ-4",
        "outputId": "b76d0cd8-28b0-4d1f-94cc-8c2e352716b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PCollection[[5]: Write others/Write/WriteImpl/FinalizeWrite.None] at 0x7bbc68a64e60>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 6: Composite Transform Example ---\n",
        "class CountVisitsTransform(beam.PTransform):\n",
        "    def expand(self, pcoll):\n",
        "        return (\n",
        "            pcoll\n",
        "            | \"Pair each patient with 1\" >> beam.Map(lambda x: (x.split(\",\")[1], 1))\n",
        "            | \"Count visits per patient\" >> beam.CombinePerKey(sum)\n",
        "            | \"Format output\" >> beam.Map(lambda kv: f\"{kv[0]} visited {kv[1]} time(s)\")\n",
        "        )\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "    (\n",
        "        p\n",
        "        | \"Read File\" >> beam.io.ReadFromText(\"dept_data.txt\")\n",
        "        | \"Apply Custom Transform\" >> CountVisitsTransform()\n",
        "        | \"Write Results\" >> beam.io.WriteToText(\"composite_output\")\n",
        "    )\n"
      ],
      "metadata": {
        "id": "BB8mUm3DwL2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 7: Windowing Example ---\n",
        "import time\n",
        "from apache_beam.transforms import window\n",
        "\n",
        "data_with_timestamps = [\n",
        "    beam.window.TimestampedValue(\"cardio\", int(time.time())),\n",
        "    beam.window.TimestampedValue(\"ortho\", int(time.time()) + 5),\n",
        "    beam.window.TimestampedValue(\"cardio\", int(time.time()) + 10),\n",
        "    beam.window.TimestampedValue(\"neuro\", int(time.time()) + 15),\n",
        "]\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "    (\n",
        "        p\n",
        "        | \"Create Data\" >> beam.Create(data_with_timestamps)\n",
        "        | \"Apply Fixed Window\" >> beam.WindowInto(window.FixedWindows(10))\n",
        "        | \"Count per Window\" >> beam.combiners.Count.PerElement()\n",
        "        | \"Print results\" >> beam.Map(print)\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMUAck3OwOci",
        "outputId": "383b1529-e5b1-4e0e-8dcb-d98e895d6ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('cardio', 1)\n",
            "('cardio', 1)\n",
            "('ortho', 1)\n",
            "('neuro', 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 8: Beam ML RunInference Example (Colab Fixed Version) ---\n",
        "\n",
        "import apache_beam as beam\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from apache_beam.ml.inference.base import RunInference\n",
        "from apache_beam.ml.inference.sklearn_inference import ModelFileType, SklearnModelHandlerNumpy\n",
        "\n",
        "# ✅ Download the model locally (instead of gs://)\n",
        "model_url = \"https://storage.googleapis.com/apache-beam-samples/run_inference/five_times_table_sklearn.pkl\"\n",
        "urllib.request.urlretrieve(model_url, \"five_times_table_sklearn.pkl\")\n",
        "\n",
        "# ✅ Create the model handler from the local file\n",
        "model_handler = SklearnModelHandlerNumpy(\n",
        "    model_uri=\"five_times_table_sklearn.pkl\",\n",
        "    model_file_type=ModelFileType.PICKLE\n",
        ")\n",
        "\n",
        "# ✅ Input data\n",
        "unkeyed_data = np.array([10, 20, 30], dtype=np.float32).reshape(-1, 1)\n",
        "\n",
        "# ✅ Run the inference pipeline\n",
        "with beam.Pipeline() as p:\n",
        "    (\n",
        "        p\n",
        "        | \"Create Inputs\" >> beam.Create(unkeyed_data)\n",
        "        | \"Run Inference\" >> RunInference(model_handler=model_handler)\n",
        "        | \"Show Predictions\" >> beam.Map(print)\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bUu848mwQ3c",
        "outputId": "306f3574-8f30-420e-9c5e-002282a7dc2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PredictionResult(example=array([10.], dtype=float32), inference=array([50.], dtype=float32), model_id='five_times_table_sklearn.pkl')\n",
            "PredictionResult(example=array([20.], dtype=float32), inference=array([100.], dtype=float32), model_id='five_times_table_sklearn.pkl')\n",
            "PredictionResult(example=array([30.], dtype=float32), inference=array([150.], dtype=float32), model_id='five_times_table_sklearn.pkl')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LinearRegression from version 1.0.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✅ Apache Beam Data Engineering Exercise\n",
        "\n",
        "**Features Demonstrated:**\n",
        "- Pipeline I/O (ReadFromText, WriteToText)\n",
        "- Map, Filter\n",
        "- ParDo\n",
        "- Partition\n",
        "- CompositeTransform\n",
        "- Windowing\n",
        "- Bonus: Beam ML RunInference\n",
        "\n",
        "**Theme:** Hospital Visit Analyzer\n",
        "\n",
        "**Execution Environment:** Google Colab (Python SDK, DirectRunner)\n",
        "\n",
        "**Video Walkthrough Outline:**\n",
        "1. Introduction & setup\n",
        "2. I/O demonstration\n",
        "3. Map/Filter explanation\n",
        "4. ParDo custom DoFn\n",
        "5. Partitioned outputs\n",
        "6. Composite reusable transform\n",
        "7. Windowing example\n",
        "8. Bonus ML inference\n"
      ],
      "metadata": {
        "id": "tR1_W5dewWeT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NlgjG6nxwUEK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}